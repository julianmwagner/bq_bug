{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pamillia_analyis\n",
    "import cv2\n",
    "\n",
    "import re\n",
    "import os.path\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.util\n",
    "import skimage.morphology\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import radon, rescale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(\"C:/Users/jwagne/Desktop/pamillia_spme_metadata_v2.xlsx\", sheet_name='Sheet1')\n",
    "\n",
    "DLC_prefix = \"C:/Users/jwagne/git/pamillia_only-julian_wagner-2020-08-05/videos/\"\n",
    "DLC_postfix = \"DLC_resnet50_pamillia_onlyAug5shuffle1_150000.h5\"\n",
    "dlc_files_1 = [re.sub('/volume1/Parker_lab/julian/[^/]+/', DLC_prefix, re.sub('.fmf', DLC_postfix, metadata.iloc[i]['video_file'])) for i in range(len(metadata))]\n",
    "\n",
    "DLC_postfix = \"DLC_resnet50_pamillia_onlyAug5shuffle1_250000.h5\"\n",
    "dlc_files_2 = [re.sub('/volume1/Parker_lab/julian/[^/]+/', DLC_prefix, re.sub('.fmf', DLC_postfix, metadata.iloc[i]['video_file'])) for i in range(len(metadata))]\n",
    "metadata['DLC_file'] = [*dlc_files_1[0:16], *dlc_files_2[16:]]\n",
    "\n",
    "vid_prefix = \"C:/Users/jwagne/git/pamillia_only-julian_wagner-2020-08-05/videos/\"\n",
    "vid_postfix = \".mp4\"\n",
    "local_vid_files = [re.sub('/volume1/Parker_lab/julian/[^/]+/', vid_prefix, re.sub('.fmf', vid_postfix, metadata.iloc[i]['video_file'])) for i in range(len(metadata))]\n",
    "metadata['video_file_local'] = local_vid_files\n",
    "\n",
    "metadata['timestamp_file'] = [*[re.sub('.mp4', '_timestamps.csv', metadata.iloc[i]['video_file_local']) for i in range(len(metadata))][0:16],\n",
    "                              *[re.sub('.mp4', '.csv', metadata.iloc[i]['video_file_local']) for i in range(len(metadata))][16:]]\n",
    "\n",
    "x1_crops = [160,  150,  150,  150,  150,  140,  145,  155,  155,  185,  185,  180,  180,  185,  180,  185,\n",
    "            160,  160,  160,  155,  160,  155,  150,  165,  160,  160,  160,  165,  165,  160,  160,  165]\n",
    "x2_crops = [1230, 1230, 1225, 1225, 1240, 1235, 1235, 1235, 1240, 1280, 1280, 1280, 1275, 1280, 1280, 1280,\n",
    "            1250, 1255, 1255, 1245, 1250, 1245, 1245, 1260, 1260, 1260, 1260, 1260, 1260, 1260, 1255, 1260]\n",
    "\n",
    "metadata['x1_crop'] = x1_crops\n",
    "metadata['x2_crop'] = x2_crops\n",
    "\n",
    "metadata['pixPerMm'] = (metadata['x2_crop']-metadata['x1_crop'])/35\n",
    "\n",
    "print(metadata['DLC_file'][0])\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the bug is using its gland for defense, another behavioral readout that may elicit gland usage are close encounters with ants. Hence, the next analysis approach will quantify how close the bug is to an ant at all times in the arena, as well as extract the amount of time the bug was 'close' to the ant based on a threshold. The algorithmic approach here goes like this:\n",
    "1) Use [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut) (DLC) to locate the position of the bug, and label points along its body  \n",
    "2) Background subtract from the behavioral video to get clean capture of animal positions  \n",
    "3) Remove the bug from the frame using the DLC positions  \n",
    "4) Use thresholding to locate ant positions as blobs  \n",
    "5) Find smallest distance from the ant positions to the bug with blob positions and DLC data\n",
    "\n",
    "\n",
    "In order to do this, we first construct background models for the videos by applying a median filter to the several frames in the videos with large amounts of time between frames. Since the animals are moving around the arena, if we use a median filter and take the dark pixels from an array of different frames (these videos are top lit against a dark background), this will eliminate the animals and leave the darker background pixel values. We generate the background images here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ims = []\n",
    "bg_im_dict = {}\n",
    "#cap.release()\n",
    "buffer_spme = 20\n",
    "for ind in tqdm.notebook.tqdm(range(len(metadata))):\n",
    "    \n",
    "    if ';' in metadata.iloc[ind]['video_file']:\n",
    "        file1, file2 = re.match('([^;]+);([^;]+)', metadata.iloc[ind]['video_file']).groups()\n",
    "        for il, file in enumerate([file1, file2]):\n",
    "            file = re.sub('.fmf', '.mp4', file)\n",
    "            file = re.sub('/volume1/Parker_lab', 'Z:', file)\n",
    "            \n",
    "            start_time=0\n",
    "            if il == 0:\n",
    "                start_time = metadata.iloc[ind]['SPME_start_time'] + buffer_spme\n",
    "            stop_time = metadata.iloc[ind]['SPME_stop_time'] - buffer_spme\n",
    "            frame_rate = 25\n",
    "\n",
    "            cap = cv2.VideoCapture(file)\n",
    "            frames = []\n",
    "            for inds in np.linspace(start_time*frame_rate, cap.get(7)-1, 30).astype(int):\n",
    "                cap.set(1, inds)\n",
    "                ret, frame = cap.read()\n",
    "                frames.append(skimage.img_as_float32(frame[:, :, 0]))\n",
    "            bg_ims.append((np.percentile(np.array(frames), q=0.1, axis=0), file))\n",
    "            bg_im_dict[metadata.iloc[ind]['video_file']] = ind\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        raw_file_name = metadata.iloc[ind]['video_file']\n",
    "        file = re.sub('.fmf', '.mp4', metadata.iloc[ind]['video_file'])\n",
    "        file = re.sub('/volume1/Parker_lab', 'Z:', file)\n",
    "\n",
    "        start_time = metadata.iloc[ind]['SPME_start_time'] + buffer_spme\n",
    "        stop_time = metadata.iloc[ind]['SPME_stop_time'] - buffer_spme\n",
    "        frame_rate = 25\n",
    "        \n",
    "        cap = cv2.VideoCapture(file)\n",
    "        frames = []\n",
    "        for inds in np.linspace(start_time*frame_rate, stop_time*frame_rate, 30).astype(int):\n",
    "            cap.set(1, inds)\n",
    "            ret, frame = cap.read()\n",
    "            frames.append(skimage.img_as_float32(frame[:, :, 0]))\n",
    "        bg_ims.append((np.percentile(np.array(frames), q=0.1, axis=0), file))\n",
    "        bg_im_dict[raw_file_name] = ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep args for multiproccessing on all vids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []\n",
    "include_bools = (metadata['interactor'] == '5_locc') | (metadata['interactor'] == '5_locc_glued')\n",
    "for ind in range(len(metadata)):\n",
    "    if not include_bools[ind]:\n",
    "        continue\n",
    "    \n",
    "    if ';' in metadata.iloc[ind]['video_file']:\n",
    "        continue\n",
    "        \n",
    "    vid_name = re.sub('.mp4', '_blob_dist_an_vid.mp4', metadata.iloc[ind]['video_file_local'])\n",
    "    x1_crop = metadata.iloc[ind]['x1_crop']\n",
    "    x2_crop = metadata.iloc[ind]['x2_crop']\n",
    "    start_ind = int(metadata.iloc[ind]['SPME_start_time']*25)\n",
    "    stop_ind = int(metadata.iloc[ind]['SPME_stop_time']*25)\n",
    "    ine = np.linspace(start_ind, stop_ind, (stop_ind-start_ind+1)).astype(int)#[31529:31533]\n",
    "    \n",
    "    args.append((metadata, \n",
    "                 bg_ims,\n",
    "                 bg_im_dict,\n",
    "                 0.05, #thresh\n",
    "                 ind, #ind\n",
    "                 ine, #ine\n",
    "                 1000, #min_size\n",
    "                 x1_crop, #x1_crop\n",
    "                 x2_crop, #x2_crop\n",
    "                 (20, 30, 30, 30, 20), #ball_rads\n",
    "                 20, #buffer_spme\n",
    "                 25, #frame_rate\n",
    "                 ['bh', 'bt1', 'bt2', 'ba1', 'ba2'], #parts\n",
    "                 0.5, #likelihood_thresh\n",
    "                 True, #give_ims\n",
    "                 True, #save_vid\n",
    "                 vid_name, #vid_name\n",
    "                 'DLC_resnet50_pamillia_onlyAug5shuffle1_150000', #network\n",
    "                 10, #erode_amount\n",
    "                 10, #dilate_amount\n",
    "                 False, #return_ims\n",
    "                 100, #part_shift_thresh\n",
    "                 'video_file_local' #vid_col\n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run analysis of distance to blobs on all vids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_proc_pamillia_dists(arguments, proc_num=14):\n",
    "    if __name__ == '__main__':\n",
    "        with multiprocessing.Pool(processes = proc_num) as pool:\n",
    "            result = pool.starmap(pamillia_analyis.ant_blobs_dists, arguments)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
